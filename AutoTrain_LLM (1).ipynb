{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface\n",
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "JlaAIgCOkQJ6",
        "outputId": "2e4b092d-4602-48e6-8327-f4efa8b68e0c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: huggingface in /usr/local/lib/python3.10/dist-packages (0.0.1)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.19.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets) (2024.3.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.3.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"garage-bAInd/Open-Platypus\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "03974b49f6ae49e187e3c6f0e0c93a15",
            "2c9587db2b25402682871d2dccb7c6c7",
            "c6b870ac173f41d2bbd76043373e5d22",
            "80c3497ff05b472b955ac61bdea7c0e0",
            "0e3cd45b9a0b4ea7a1d877b9a40a74f7",
            "f5691a37da8c4a899167a8be7a41b8f3",
            "0f115277493144239079f87a2bfb547e",
            "553c02810a084785ba0428e2f66e537b",
            "181e6e0992e14651b796e0b4e5c9830b",
            "5d39950daec34c138e61962cf7404b2d",
            "0e89ed236c0647d3b2d4e8edd30059c3"
          ]
        },
        "id": "AHm6ob2Kk1TW",
        "outputId": "d37177dc-bdbb-49e7-b3a0-d9764a969c39"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/5.34k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "03974b49f6ae49e187e3c6f0e0c93a15"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_text_column(example):\n",
        "    example['text'] = (f\"Instruction: {example['instruction']}\\n\"\n",
        "                       f\"Input: {example['input']}\\n\"\n",
        "                       f\"Output: {example['output']}\")\n",
        "    return example"
      ],
      "metadata": {
        "id": "LeK3Gto9mbU_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds['train'] = ds['train'].map(create_text_column, remove_columns=['instruction', 'input', 'output'])\n",
        "\n",
        "\n",
        "# Print the first example to verify\n",
        "print(ds['train'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rKMcITmJtqB",
        "outputId": "ca019581-b7a8-4e84-e76b-fddddf311014"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'data_source': 'MATH/PRM-800K', 'text': 'Instruction: A board game spinner is divided into three parts labeled $A$, $B$  and $C$. The probability of the spinner landing on $A$ is $\\\\frac{1}{3}$ and the probability of the spinner landing on $B$ is $\\\\frac{5}{12}$.  What is the probability of the spinner landing on $C$? Express your answer as a common fraction.\\nInput: \\nOutput: To find the probability of the spinner landing on $C$, I need to subtract the probabilities of the spinner landing on $A$ and $B$ from $1$, since the sum of the probabilities of all possible outcomes is $1$. I can write this as an equation: $P(C) = 1 - P(A) - P(B)$. I know that $P(A) = \\\\frac{1}{3}$ and $P(B) = \\\\frac{5}{12}$, so I can plug those values into the equation and simplify. I get: $P(C) = 1 - \\\\frac{1}{3} - \\\\frac{5}{12} = \\\\frac{12}{12} - \\\\frac{4}{12} - \\\\frac{5}{12} = \\\\frac{3}{12}$. I can reduce this fraction by dividing the numerator and denominator by $3$, and I get: $P(C) = \\\\frac{1}{4}$. '}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_and_shuffle(dataset, split, fraction=0.5):\n",
        "    # Shuffle the dataset\n",
        "    shuffled_dataset = dataset[split].shuffle(seed=42)\n",
        "    # Calculate the number of rows to keep\n",
        "    num_rows = len(shuffled_dataset)\n",
        "    num_to_keep = int(num_rows * fraction)\n",
        "    # Select the desired fraction\n",
        "    sampled_dataset = shuffled_dataset.select(range(num_to_keep))\n",
        "    return sampled_dataset\n",
        "\n",
        "# Apply the function to each split\n",
        "ds['train'] = sample_and_shuffle(ds, 'train', fraction=0.40)"
      ],
      "metadata": {
        "id": "qFiS42tIM-Z_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#convert to csv\n",
        "ds['train'].to_csv('train.csv', index=False)"
      ],
      "metadata": {
        "id": "nlSL2zyJLQlc",
        "outputId": "9c83d6e1-cca3-4730-d734-158433cbd8e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "f02628b7b9f949e59883ac8c4091e64a",
            "ccef7bc62ce7431ebd015bc51189c381",
            "2f4f721a79d04ceba0a967a1d1d759be",
            "429f0859f87c4ad6bcdd81f09685d9ac",
            "0dc9a0da0c4c4f4f83889a401ce00a8d",
            "13942a750c404a87a51aa122fa60e19e",
            "ad13c48a4f40417a8fe229d1bc2d0c38",
            "b1ca68152ad14bc69de31cb73672128b",
            "86f70dabaa714e5399e85a967e085432",
            "ca5dd14ec11f43a0a6aa8d38a8e13714",
            "afeccb4d3c4e4da0abd7748105f25f46"
          ]
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Creating CSV from Arrow format:   0%|          | 0/4 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f02628b7b9f949e59883ac8c4091e64a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4682179"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "id": "JvMRbVLEJlZT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d904b69c-7419-4f46-97cd-33cc5513b3ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AutoTrain version: 0.8.12\n"
          ]
        }
      ],
      "source": [
        "#@title 🤗 AutoTrain LLM\n",
        "#@markdown In order to use this colab\n",
        "#@markdown - upload train.csv to a folder named `data/`\n",
        "#@markdown - train.csv must contain a `text` column\n",
        "#@markdown - choose a project name if you wish\n",
        "#@markdown - change model if you wish, you can use most of the text-generation models from Hugging Face Hub\n",
        "#@markdown - add huggingface information (token) if you wish to push trained model to huggingface hub\n",
        "#@markdown - update hyperparameters if you wish\n",
        "#@markdown - click `Runtime > Run all` or run each cell individually\n",
        "#@markdown - report issues / feature requests here: https://github.com/huggingface/autotrain-advanced/issues\n",
        "\n",
        "\n",
        "import os\n",
        "!pip install -U autotrain-advanced > install_logs.txt 2>&1\n",
        "!autotrain setup --colab > setup_logs.txt\n",
        "from autotrain import __version__\n",
        "print(f'AutoTrain version: {__version__}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "!pip install --force-reinstall torch==2.3.0\n",
        "\n",
        "from torch import __version__\n",
        "print(f'Torch version: {__version__}')\n"
      ],
      "metadata": {
        "id": "qwjLDC3yuQtR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a66207ed-63e9-467a-b057-c54e9bcb2a84"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting torch==2.3.0\n",
            "  Downloading torch-2.3.0-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Collecting filelock (from torch==2.3.0)\n",
            "  Using cached filelock-3.15.4-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting typing-extensions>=4.8.0 (from torch==2.3.0)\n",
            "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting sympy (from torch==2.3.0)\n",
            "  Using cached sympy-1.13.2-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx (from torch==2.3.0)\n",
            "  Using cached networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting jinja2 (from torch==2.3.0)\n",
            "  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting fsspec (from torch==2.3.0)\n",
            "  Using cached fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.0)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.0)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.0)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.0)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.0)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.0)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.0)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.0)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.0)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.0)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.0)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.3.0 (from torch==2.3.0)\n",
            "  Downloading triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch==2.3.0)\n",
            "  Using cached MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch==2.3.0)\n",
            "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Downloading torch-2.3.0-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Using cached filelock-3.15.4-py3-none-any.whl (16 kB)\n",
            "Using cached fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
            "Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
            "Using cached networkx-3.3-py3-none-any.whl (1.7 MB)\n",
            "Using cached sympy-1.13.2-py3-none-any.whl (6.2 MB)\n",
            "Using cached MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: mpmath, typing-extensions, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, MarkupSafe, fsspec, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch\n",
            "  Attempting uninstall: mpmath\n",
            "    Found existing installation: mpmath 1.3.0\n",
            "    Uninstalling mpmath-1.3.0:\n",
            "      Successfully uninstalled mpmath-1.3.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.12.2\n",
            "    Uninstalling typing_extensions-4.12.2:\n",
            "      Successfully uninstalled typing_extensions-4.12.2\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.2\n",
            "    Uninstalling sympy-1.13.2:\n",
            "      Successfully uninstalled sympy-1.13.2\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.1.105\n",
            "    Uninstalling nvidia-nvtx-cu12-12.1.105:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.1.105\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.6.20\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.6.20:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.20\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.19.3\n",
            "    Uninstalling nvidia-nccl-cu12-2.19.3:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.19.3\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.2.106\n",
            "    Uninstalling nvidia-curand-cu12-10.3.2.106:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.2.106\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.0.2.54\n",
            "    Uninstalling nvidia-cufft-cu12-11.0.2.54:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.0.2.54\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.1.105\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.1.105:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.1.105\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.1.105\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.1.105:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.1.105\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.1.105\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.1.105:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.1.105\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.1.3.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.1.3.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.1.3.1\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.3\n",
            "    Uninstalling networkx-3.3:\n",
            "      Successfully uninstalled networkx-3.3\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 2.1.5\n",
            "    Uninstalling MarkupSafe-2.1.5:\n",
            "      Successfully uninstalled MarkupSafe-2.1.5\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.3.1\n",
            "    Uninstalling fsspec-2024.3.1:\n",
            "      Successfully uninstalled fsspec-2024.3.1\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.15.4\n",
            "    Uninstalling filelock-3.15.4:\n",
            "      Successfully uninstalled filelock-3.15.4\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.2.0\n",
            "    Uninstalling triton-2.2.0:\n",
            "      Successfully uninstalled triton-2.2.0\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.1.0.106\n",
            "    Uninstalling nvidia-cusparse-cu12-12.1.0.106:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.1.0.106\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 8.9.2.26\n",
            "    Uninstalling nvidia-cudnn-cu12-8.9.2.26:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-8.9.2.26\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.4\n",
            "    Uninstalling Jinja2-3.1.4:\n",
            "      Successfully uninstalled Jinja2-3.1.4\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.4.5.107\n",
            "    Uninstalling nvidia-cusolver-cu12-11.4.5.107:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.4.5.107\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.2.0\n",
            "    Uninstalling torch-2.2.0:\n",
            "      Successfully uninstalled torch-2.2.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you have pandas 2.2.2 which is incompatible.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "datasets 2.19.1 requires fsspec[http]<=2024.3.1,>=2023.1.0, but you have fsspec 2024.6.1 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\n",
            "tensorflow 2.17.0 requires tensorboard<2.18,>=2.17, but you have tensorboard 2.16.2 which is incompatible.\n",
            "torchaudio 2.3.1+cu121 requires torch==2.3.1, but you have torch 2.3.0 which is incompatible.\n",
            "torchvision 0.18.1+cu121 requires torch==2.3.1, but you have torch 2.3.0 which is incompatible.\n",
            "xformers 0.0.24 requires torch==2.2.0, but you have torch 2.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-2.1.5 filelock-3.15.4 fsspec-2024.6.1 jinja2-3.1.4 mpmath-1.3.0 networkx-3.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 sympy-1.13.2 torch-2.3.0 triton-2.3.0 typing-extensions-4.12.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "mpmath",
                  "sympy",
                  "torch",
                  "torchgen"
                ]
              },
              "id": "fbe35f2cf95643949c2e4c4615dda3af"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch version: 2.2.0+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "cellView": "form",
        "id": "A2-_lkBS1WKA"
      },
      "outputs": [],
      "source": [
        "#@markdown ---\n",
        "#@markdown #### Project Config\n",
        "#@markdown Note: if you are using a restricted/private model, you need to enter your Hugging Face token in the next step.\n",
        "project_name = 'Llama2STEM' # @param {type:\"string\"}\n",
        "model_name = 'TinyPixel/Llama-2-7B-bf16-sharded' # @param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Push to Hub?\n",
        "#@markdown Use these only if you want to push your trained model to a private repo in your Hugging Face Account\n",
        "#@markdown If you dont use these, the model will be saved in Google Colab and you are required to download it manually.\n",
        "#@markdown Please enter your Hugging Face write token. The trained model will be saved to your Hugging Face account.\n",
        "#@markdown You can find your token here: https://huggingface.co/settings/tokens\n",
        "push_to_hub = True # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "hf_token = \"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\" #@param {type:\"string\"}\n",
        "hf_username = \"AzmeerFaisal\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### Hyperparameters\n",
        "unsloth = False # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "learning_rate = 2e-4 # @param {type:\"number\"}\n",
        "num_epochs = 1 #@param {type:\"number\"}\n",
        "batch_size = 1 # @param {type:\"slider\", min:1, max:32, step:1}\n",
        "block_size = 1024 # @param {type:\"number\"}\n",
        "trainer = \"sft\" # @param [\"generic\", \"sft\"] {type:\"string\"}\n",
        "warmup_ratio = 0.1 # @param {type:\"number\"}\n",
        "weight_decay = 0.01 # @param {type:\"number\"}\n",
        "gradient_accumulation = 4 # @param {type:\"number\"}\n",
        "mixed_precision = \"fp16\" # @param [\"fp16\", \"bf16\", \"none\"] {type:\"string\"}\n",
        "peft = True # @param [\"False\", \"True\"] {type:\"raw\"}\n",
        "quantization = \"int4\" # @param [\"int4\", \"int8\", \"none\"] {type:\"string\"}\n",
        "lora_r = 16 #@param {type:\"number\"}\n",
        "lora_alpha = 32 #@param {type:\"number\"}\n",
        "lora_dropout = 0.05 #@param {type:\"number\"}\n",
        "\n",
        "os.environ[\"HF_TOKEN\"] = hf_token\n",
        "os.environ[\"HF_USERNAME\"] = hf_username\n",
        "\n",
        "conf = f\"\"\"\n",
        "task: llm-{trainer}\n",
        "base_model: {model_name}\n",
        "project_name: {project_name}\n",
        "log: tensorboard\n",
        "backend: local\n",
        "\n",
        "data:\n",
        "  path: /content\n",
        "  train_split: train\n",
        "  valid_split: null\n",
        "  chat_template: null\n",
        "  column_mapping:\n",
        "    text_column: text\n",
        "\n",
        "params:\n",
        "  block_size: {block_size}\n",
        "  lr: {learning_rate}\n",
        "  warmup_ratio: {warmup_ratio}\n",
        "  weight_decay: {weight_decay}\n",
        "  epochs: {num_epochs}\n",
        "  batch_size: {batch_size}\n",
        "  gradient_accumulation: {gradient_accumulation}\n",
        "  mixed_precision: {mixed_precision}\n",
        "  peft: {peft}\n",
        "  quantization: {quantization}\n",
        "  lora_r: {lora_r}\n",
        "  lora_alpha: {lora_alpha}\n",
        "  lora_dropout: {lora_dropout}\n",
        "  unsloth: {unsloth}\n",
        "\n",
        "hub:\n",
        "  username: ${{HF_USERNAME}}\n",
        "  token: ${{HF_TOKEN}}\n",
        "  push_to_hub: {push_to_hub}\n",
        "\"\"\"\n",
        "\n",
        "with open(\"conf.yaml\", \"w\") as f:\n",
        "  f.write(conf)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UuNWGZ0akOp9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "g3cd_ED_yXXt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3848138-d830-4fc7-d605-629a130e339f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-08-21 18:36:43\u001b[0m | \u001b[36mautotrain.cli.autotrain\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m60\u001b[0m - \u001b[1mUsing AutoTrain configuration: conf.yaml\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-08-21 18:36:44\u001b[0m | \u001b[36mautotrain.parser\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m147\u001b[0m - \u001b[1mRunning task: lm_training\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-08-21 18:36:44\u001b[0m | \u001b[36mautotrain.parser\u001b[0m:\u001b[36m__post_init__\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1mUsing backend: local\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-08-21 18:36:44\u001b[0m | \u001b[36mautotrain.parser\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m211\u001b[0m - \u001b[1m{'model': 'TinyPixel/Llama-2-7B-bf16-sharded', 'project_name': 'Llama2STEM', 'data_path': '/content', 'train_split': 'train', 'valid_split': None, 'add_eos_token': True, 'block_size': 1024, 'model_max_length': 2048, 'padding': 'right', 'trainer': 'sft', 'use_flash_attention_2': False, 'log': 'tensorboard', 'disable_gradient_checkpointing': False, 'logging_steps': -1, 'eval_strategy': 'epoch', 'save_total_limit': 1, 'auto_find_batch_size': False, 'mixed_precision': 'fp16', 'lr': 0.0002, 'epochs': 3, 'batch_size': 1, 'warmup_ratio': 0.1, 'gradient_accumulation': 4, 'optimizer': 'adamw_torch', 'scheduler': 'linear', 'weight_decay': 0.01, 'max_grad_norm': 1.0, 'seed': 42, 'chat_template': None, 'quantization': 'int4', 'target_modules': 'all-linear', 'merge_adapter': False, 'peft': True, 'lora_r': 16, 'lora_alpha': 32, 'lora_dropout': 0.05, 'model_ref': None, 'dpo_beta': 0.1, 'max_prompt_length': 128, 'max_completion_length': None, 'prompt_text_column': None, 'text_column': 'text', 'rejected_text_column': None, 'push_to_hub': True, 'username': 'AzmeerFaisal', 'token': '*****', 'unsloth': False}\u001b[0m\n",
            "Saving the dataset (1/1 shards): 100% 3738/3738 [00:00<00:00, 442527.54 examples/s]\n",
            "Saving the dataset (1/1 shards): 100% 3738/3738 [00:00<00:00, 555672.81 examples/s]\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-08-21 18:36:44\u001b[0m | \u001b[36mautotrain.backends.local\u001b[0m:\u001b[36mcreate\u001b[0m:\u001b[36m8\u001b[0m - \u001b[1mStarting local training...\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-08-21 18:36:44\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m489\u001b[0m - \u001b[1m['accelerate', 'launch', '--num_machines', '1', '--num_processes', '1', '--mixed_precision', 'fp16', '-m', 'autotrain.trainers.clm', '--training_config', 'Llama2STEM/training_params.json']\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-08-21 18:36:44\u001b[0m | \u001b[36mautotrain.commands\u001b[0m:\u001b[36mlaunch_command\u001b[0m:\u001b[36m490\u001b[0m - \u001b[1m{'model': 'TinyPixel/Llama-2-7B-bf16-sharded', 'project_name': 'Llama2STEM', 'data_path': 'Llama2STEM/autotrain-data', 'train_split': 'train', 'valid_split': None, 'add_eos_token': True, 'block_size': 1024, 'model_max_length': 2048, 'padding': 'right', 'trainer': 'sft', 'use_flash_attention_2': False, 'log': 'tensorboard', 'disable_gradient_checkpointing': False, 'logging_steps': -1, 'eval_strategy': 'epoch', 'save_total_limit': 1, 'auto_find_batch_size': False, 'mixed_precision': 'fp16', 'lr': 0.0002, 'epochs': 3, 'batch_size': 1, 'warmup_ratio': 0.1, 'gradient_accumulation': 4, 'optimizer': 'adamw_torch', 'scheduler': 'linear', 'weight_decay': 0.01, 'max_grad_norm': 1.0, 'seed': 42, 'chat_template': None, 'quantization': 'int4', 'target_modules': 'all-linear', 'merge_adapter': False, 'peft': True, 'lora_r': 16, 'lora_alpha': 32, 'lora_dropout': 0.05, 'model_ref': None, 'dpo_beta': 0.1, 'max_prompt_length': 128, 'max_completion_length': None, 'prompt_text_column': 'autotrain_prompt', 'text_column': 'autotrain_text', 'rejected_text_column': 'autotrain_rejected_text', 'push_to_hub': True, 'username': 'AzmeerFaisal', 'token': '*****', 'unsloth': False}\u001b[0m\n",
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-08-21 18:36:59\u001b[0m | \u001b[36mautotrain.trainers.clm.train_clm_sft\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mStarting SFT training...\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-08-21 18:36:59\u001b[0m | \u001b[36mautotrain.trainers.clm.utils\u001b[0m:\u001b[36mprocess_input_data\u001b[0m:\u001b[36m335\u001b[0m - \u001b[1mloading dataset from disk\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-08-21 18:36:59\u001b[0m | \u001b[36mautotrain.trainers.clm.utils\u001b[0m:\u001b[36mprocess_input_data\u001b[0m:\u001b[36m394\u001b[0m - \u001b[1mTrain data: Dataset({\n",
            "    features: ['data_source', 'autotrain_text'],\n",
            "    num_rows: 3738\n",
            "})\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-08-21 18:36:59\u001b[0m | \u001b[36mautotrain.trainers.clm.utils\u001b[0m:\u001b[36mprocess_input_data\u001b[0m:\u001b[36m395\u001b[0m - \u001b[1mValid data: None\u001b[0m\n",
            "tokenizer_config.json: 100% 676/676 [00:00<00:00, 4.37MB/s]\n",
            "tokenizer.model: 100% 500k/500k [00:00<00:00, 15.0MB/s]\n",
            "tokenizer.json: 100% 1.84M/1.84M [00:00<00:00, 7.32MB/s]\n",
            "special_tokens_map.json: 100% 411/411 [00:00<00:00, 2.71MB/s]\n",
            "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama_fast.LlamaTokenizerFast'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message.\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-08-21 18:37:01\u001b[0m | \u001b[36mautotrain.trainers.clm.utils\u001b[0m:\u001b[36mconfigure_logging_steps\u001b[0m:\u001b[36m467\u001b[0m - \u001b[1mconfiguring logging steps\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-08-21 18:37:01\u001b[0m | \u001b[36mautotrain.trainers.clm.utils\u001b[0m:\u001b[36mconfigure_logging_steps\u001b[0m:\u001b[36m480\u001b[0m - \u001b[1mLogging steps: 25\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-08-21 18:37:01\u001b[0m | \u001b[36mautotrain.trainers.clm.utils\u001b[0m:\u001b[36mconfigure_training_args\u001b[0m:\u001b[36m485\u001b[0m - \u001b[1mconfiguring training args\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-08-21 18:37:01\u001b[0m | \u001b[36mautotrain.trainers.clm.utils\u001b[0m:\u001b[36mconfigure_block_size\u001b[0m:\u001b[36m548\u001b[0m - \u001b[1mUsing block size 1024\u001b[0m\n",
            "config.json: 100% 626/626 [00:00<00:00, 3.33MB/s]\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-08-21 18:37:01\u001b[0m | \u001b[36mautotrain.trainers.clm.utils\u001b[0m:\u001b[36mget_model\u001b[0m:\u001b[36m583\u001b[0m - \u001b[1mCan use unsloth: False\u001b[0m\n",
            "\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[32m2024-08-21 18:37:01\u001b[0m | \u001b[36mautotrain.trainers.clm.utils\u001b[0m:\u001b[36mget_model\u001b[0m:\u001b[36m625\u001b[0m - \u001b[33m\u001b[1mUnsloth not available, continuing without it...\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-08-21 18:37:01\u001b[0m | \u001b[36mautotrain.trainers.clm.utils\u001b[0m:\u001b[36mget_model\u001b[0m:\u001b[36m627\u001b[0m - \u001b[1mloading model config...\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-08-21 18:37:01\u001b[0m | \u001b[36mautotrain.trainers.clm.utils\u001b[0m:\u001b[36mget_model\u001b[0m:\u001b[36m635\u001b[0m - \u001b[1mloading model...\u001b[0m\n",
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
            "model.safetensors.index.json: 100% 28.1k/28.1k [00:00<00:00, 112MB/s]\n",
            "Downloading shards:   0% 0/14 [00:00<?, ?it/s]\n",
            "model-00001-of-00014.safetensors:   0% 0.00/981M [00:00<?, ?B/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:   3% 31.5M/981M [00:00<00:03, 245MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:   6% 62.9M/981M [00:00<00:03, 272MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  10% 94.4M/981M [00:00<00:03, 289MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  13% 126M/981M [00:00<00:02, 289MB/s] \u001b[A\n",
            "model-00001-of-00014.safetensors:  16% 157M/981M [00:00<00:03, 261MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  19% 189M/981M [00:00<00:03, 253MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  22% 220M/981M [00:00<00:02, 258MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  26% 252M/981M [00:00<00:02, 262MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  29% 283M/981M [00:01<00:02, 262MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  32% 315M/981M [00:01<00:02, 264MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  35% 346M/981M [00:01<00:02, 257MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  38% 377M/981M [00:01<00:02, 265MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  42% 409M/981M [00:01<00:02, 265MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  45% 440M/981M [00:01<00:02, 261MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  48% 472M/981M [00:01<00:01, 259MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  51% 503M/981M [00:01<00:02, 238MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  54% 535M/981M [00:02<00:01, 228MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  58% 566M/981M [00:02<00:01, 222MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  61% 598M/981M [00:02<00:01, 221MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  64% 629M/981M [00:02<00:01, 228MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  67% 661M/981M [00:02<00:01, 210MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  71% 692M/981M [00:02<00:01, 223MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  74% 724M/981M [00:02<00:01, 241MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  77% 755M/981M [00:03<00:00, 241MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  80% 786M/981M [00:03<00:00, 236MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  83% 818M/981M [00:03<00:00, 210MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  87% 849M/981M [00:03<00:00, 204MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  90% 881M/981M [00:03<00:00, 208MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  93% 912M/981M [00:03<00:00, 207MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors:  96% 944M/981M [00:03<00:00, 213MB/s]\u001b[A\n",
            "model-00001-of-00014.safetensors: 100% 981M/981M [00:04<00:00, 234MB/s]\n",
            "Downloading shards:   7% 1/14 [00:04<00:56,  4.31s/it]\n",
            "model-00002-of-00014.safetensors:   0% 0.00/967M [00:00<?, ?B/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:   3% 31.5M/967M [00:00<00:03, 260MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:   7% 62.9M/967M [00:00<00:03, 263MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  10% 94.4M/967M [00:00<00:03, 247MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  13% 126M/967M [00:00<00:03, 237MB/s] \u001b[A\n",
            "model-00002-of-00014.safetensors:  16% 157M/967M [00:00<00:04, 192MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  18% 178M/967M [00:00<00:04, 181MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  21% 199M/967M [00:00<00:04, 185MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  23% 220M/967M [00:01<00:03, 189MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  26% 252M/967M [00:01<00:03, 209MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  29% 283M/967M [00:01<00:03, 225MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  33% 315M/967M [00:01<00:02, 236MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  36% 346M/967M [00:01<00:02, 248MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  39% 377M/967M [00:01<00:02, 253MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  42% 409M/967M [00:01<00:02, 257MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  46% 440M/967M [00:01<00:02, 248MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  49% 472M/967M [00:02<00:01, 261MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  52% 503M/967M [00:02<00:01, 264MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  55% 535M/967M [00:02<00:01, 263MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  59% 566M/967M [00:02<00:01, 266MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  62% 598M/967M [00:02<00:01, 267MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  65% 629M/967M [00:02<00:01, 274MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  68% 661M/967M [00:02<00:01, 267MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  72% 692M/967M [00:02<00:01, 269MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  75% 724M/967M [00:02<00:00, 259MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  78% 755M/967M [00:03<00:00, 260MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  81% 786M/967M [00:03<00:00, 253MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  85% 818M/967M [00:03<00:00, 258MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  88% 849M/967M [00:03<00:00, 252MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  91% 881M/967M [00:03<00:00, 255MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors:  94% 912M/967M [00:03<00:00, 254MB/s]\u001b[A\n",
            "model-00002-of-00014.safetensors: 100% 967M/967M [00:03<00:00, 245MB/s]\n",
            "Downloading shards:  14% 2/14 [00:08<00:52,  4.34s/it]\n",
            "model-00003-of-00014.safetensors:   0% 0.00/967M [00:00<?, ?B/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:   2% 21.0M/967M [00:00<00:06, 146MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:   4% 41.9M/967M [00:00<00:05, 174MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:   8% 73.4M/967M [00:00<00:04, 206MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  11% 105M/967M [00:00<00:03, 219MB/s] \u001b[A\n",
            "model-00003-of-00014.safetensors:  14% 136M/967M [00:00<00:03, 222MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  17% 168M/967M [00:00<00:03, 240MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  21% 199M/967M [00:00<00:03, 247MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  24% 231M/967M [00:01<00:03, 242MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  27% 262M/967M [00:01<00:02, 241MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  30% 294M/967M [00:01<00:02, 248MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  34% 325M/967M [00:01<00:02, 248MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  37% 357M/967M [00:01<00:02, 253MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  40% 388M/967M [00:01<00:02, 256MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  43% 419M/967M [00:01<00:02, 256MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  47% 451M/967M [00:01<00:01, 260MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  50% 482M/967M [00:01<00:01, 262MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  53% 514M/967M [00:02<00:01, 253MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  56% 545M/967M [00:02<00:01, 257MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  60% 577M/967M [00:02<00:01, 258MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  63% 608M/967M [00:02<00:01, 259MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  66% 640M/967M [00:02<00:01, 259MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  69% 671M/967M [00:02<00:01, 265MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  73% 703M/967M [00:02<00:01, 253MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  76% 734M/967M [00:02<00:00, 255MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  79% 765M/967M [00:03<00:00, 255MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  82% 797M/967M [00:03<00:00, 253MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  86% 828M/967M [00:03<00:00, 250MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  89% 860M/967M [00:03<00:00, 251MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  92% 891M/967M [00:03<00:00, 251MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors:  95% 923M/967M [00:03<00:00, 256MB/s]\u001b[A\n",
            "model-00003-of-00014.safetensors: 100% 967M/967M [00:05<00:00, 185MB/s] \n",
            "Downloading shards:  21% 3/14 [00:14<00:52,  4.80s/it]\n",
            "model-00004-of-00014.safetensors:   0% 0.00/990M [00:00<?, ?B/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:   3% 31.5M/990M [00:00<00:03, 249MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:   6% 62.9M/990M [00:00<00:03, 260MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  10% 94.4M/990M [00:00<00:03, 255MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  13% 126M/990M [00:00<00:03, 245MB/s] \u001b[A\n",
            "model-00004-of-00014.safetensors:  16% 157M/990M [00:00<00:03, 237MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  19% 189M/990M [00:00<00:03, 233MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  22% 220M/990M [00:00<00:03, 238MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  25% 252M/990M [00:01<00:03, 243MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  29% 283M/990M [00:01<00:02, 247MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  32% 315M/990M [00:01<00:02, 245MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  35% 346M/990M [00:01<00:02, 250MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  38% 377M/990M [00:01<00:02, 254MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  41% 409M/990M [00:01<00:02, 261MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  44% 440M/990M [00:01<00:02, 249MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  48% 472M/990M [00:03<00:08, 58.9MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  50% 493M/990M [00:03<00:07, 70.2MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  53% 524M/990M [00:03<00:05, 90.3MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  55% 545M/990M [00:03<00:04, 102MB/s] \u001b[A\n",
            "model-00004-of-00014.safetensors:  57% 566M/990M [00:03<00:03, 116MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  59% 587M/990M [00:03<00:03, 129MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  61% 608M/990M [00:03<00:02, 138MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  64% 629M/990M [00:04<00:02, 151MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  66% 650M/990M [00:06<00:11, 30.3MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  68% 671M/990M [00:07<00:12, 25.8MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  71% 703M/990M [00:07<00:07, 39.7MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  74% 734M/990M [00:07<00:04, 57.5MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  77% 765M/990M [00:07<00:02, 76.9MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  81% 797M/990M [00:07<00:01, 99.4MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  84% 828M/990M [00:07<00:01, 120MB/s] \u001b[A\n",
            "model-00004-of-00014.safetensors:  87% 860M/990M [00:07<00:00, 143MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  90% 891M/990M [00:08<00:00, 164MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  93% 923M/990M [00:08<00:00, 180MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors:  96% 954M/990M [00:08<00:00, 201MB/s]\u001b[A\n",
            "model-00004-of-00014.safetensors: 100% 990M/990M [00:09<00:00, 101MB/s] \n",
            "Downloading shards:  29% 4/14 [00:23<01:08,  6.84s/it]\n",
            "model-00005-of-00014.safetensors:   0% 0.00/944M [00:00<?, ?B/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:   2% 21.0M/944M [00:00<00:06, 142MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:   6% 52.4M/944M [00:00<00:04, 199MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:   9% 83.9M/944M [00:00<00:03, 230MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  12% 115M/944M [00:00<00:03, 237MB/s] \u001b[A\n",
            "model-00005-of-00014.safetensors:  16% 147M/944M [00:00<00:03, 230MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  19% 178M/944M [00:00<00:03, 230MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  22% 210M/944M [00:00<00:03, 230MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  26% 241M/944M [00:01<00:02, 236MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  29% 273M/944M [00:01<00:02, 228MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  32% 304M/944M [00:01<00:02, 238MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  36% 336M/944M [00:01<00:02, 238MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  39% 367M/944M [00:01<00:02, 241MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  42% 398M/944M [00:01<00:02, 241MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  46% 430M/944M [00:01<00:02, 246MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  49% 461M/944M [00:01<00:01, 245MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  52% 493M/944M [00:02<00:01, 248MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  56% 524M/944M [00:02<00:01, 238MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  59% 556M/944M [00:02<00:01, 245MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  62% 587M/944M [00:02<00:01, 248MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  66% 619M/944M [00:02<00:01, 246MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  69% 650M/944M [00:02<00:01, 245MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  72% 682M/944M [00:02<00:01, 244MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  76% 713M/944M [00:03<00:01, 164MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  79% 744M/944M [00:03<00:01, 184MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  82% 776M/944M [00:03<00:00, 200MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  86% 807M/944M [00:03<00:00, 214MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  89% 839M/944M [00:03<00:00, 217MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  92% 870M/944M [00:03<00:00, 219MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors:  96% 902M/944M [00:03<00:00, 233MB/s]\u001b[A\n",
            "model-00005-of-00014.safetensors: 100% 944M/944M [00:04<00:00, 226MB/s]\n",
            "Downloading shards:  36% 5/14 [00:28<00:53,  5.93s/it]\n",
            "model-00006-of-00014.safetensors:   0% 0.00/990M [00:00<?, ?B/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:   3% 31.5M/990M [00:00<00:03, 270MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:   6% 62.9M/990M [00:00<00:03, 261MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  10% 94.4M/990M [00:00<00:03, 251MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  13% 126M/990M [00:00<00:03, 227MB/s] \u001b[A\n",
            "model-00006-of-00014.safetensors:  16% 157M/990M [00:00<00:04, 207MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  19% 189M/990M [00:00<00:03, 201MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  21% 210M/990M [00:01<00:04, 185MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  23% 231M/990M [00:01<00:04, 185MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  26% 262M/990M [00:01<00:03, 199MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  29% 283M/990M [00:01<00:03, 189MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  31% 304M/990M [00:01<00:03, 190MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  33% 325M/990M [00:01<00:03, 192MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  36% 357M/990M [00:01<00:03, 196MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  38% 377M/990M [00:01<00:03, 191MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  41% 409M/990M [00:02<00:02, 196MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  43% 430M/990M [00:02<00:02, 197MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  46% 451M/990M [00:02<00:02, 198MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  48% 472M/990M [00:02<00:02, 199MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  50% 493M/990M [00:02<00:02, 200MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  53% 524M/990M [00:02<00:02, 201MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  55% 545M/990M [00:02<00:02, 193MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  57% 566M/990M [00:02<00:02, 193MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  59% 587M/990M [00:02<00:02, 196MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  61% 608M/990M [00:03<00:01, 191MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  65% 640M/990M [00:03<00:01, 205MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  68% 671M/990M [00:03<00:01, 219MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  71% 703M/990M [00:03<00:01, 232MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  74% 734M/990M [00:03<00:01, 225MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  77% 765M/990M [00:03<00:01, 211MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  81% 797M/990M [00:03<00:00, 205MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  83% 818M/990M [00:04<00:00, 201MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  86% 849M/990M [00:04<00:00, 211MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  89% 881M/990M [00:04<00:00, 198MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  92% 912M/990M [00:04<00:00, 206MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  95% 944M/990M [00:04<00:00, 200MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors:  97% 965M/990M [00:04<00:00, 196MB/s]\u001b[A\n",
            "model-00006-of-00014.safetensors: 100% 990M/990M [00:04<00:00, 201MB/s]\n",
            "Downloading shards:  43% 6/14 [00:33<00:45,  5.64s/it]\n",
            "model-00007-of-00014.safetensors:   0% 0.00/967M [00:00<?, ?B/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:   3% 31.5M/967M [00:00<00:04, 225MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:   7% 62.9M/967M [00:00<00:04, 220MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  10% 94.4M/967M [00:00<00:10, 81.3MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  13% 126M/967M [00:01<00:07, 113MB/s]  \u001b[A\n",
            "model-00007-of-00014.safetensors:  15% 147M/967M [00:01<00:06, 124MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  17% 168M/967M [00:01<00:05, 135MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  20% 189M/967M [00:01<00:05, 144MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  22% 210M/967M [00:01<00:05, 146MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  24% 231M/967M [00:01<00:04, 148MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  26% 252M/967M [00:01<00:04, 148MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  28% 273M/967M [00:01<00:04, 158MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  31% 304M/967M [00:02<00:03, 181MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  35% 336M/967M [00:02<00:03, 201MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  38% 367M/967M [00:02<00:02, 217MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  41% 398M/967M [00:02<00:02, 218MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  44% 430M/967M [00:02<00:02, 221MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  48% 461M/967M [00:02<00:02, 236MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  51% 493M/967M [00:02<00:02, 234MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  54% 524M/967M [00:03<00:01, 242MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  57% 556M/967M [00:03<00:01, 248MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  61% 587M/967M [00:03<00:01, 243MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  64% 619M/967M [00:03<00:01, 244MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  67% 650M/967M [00:03<00:01, 242MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  70% 682M/967M [00:03<00:01, 249MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  74% 713M/967M [00:03<00:01, 241MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  77% 744M/967M [00:04<00:01, 170MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  80% 776M/967M [00:04<00:00, 194MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  84% 807M/967M [00:04<00:00, 218MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  87% 839M/967M [00:04<00:00, 230MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  90% 870M/967M [00:04<00:00, 208MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  93% 902M/967M [00:04<00:00, 219MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors:  97% 933M/967M [00:04<00:00, 224MB/s]\u001b[A\n",
            "model-00007-of-00014.safetensors: 100% 967M/967M [00:05<00:00, 193MB/s]\n",
            "Downloading shards:  50% 7/14 [00:38<00:38,  5.48s/it]\n",
            "model-00008-of-00014.safetensors:   0% 0.00/967M [00:00<?, ?B/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:   3% 31.5M/967M [00:00<00:03, 258MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:   7% 62.9M/967M [00:00<00:03, 281MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  10% 94.4M/967M [00:00<00:03, 267MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  13% 126M/967M [00:00<00:03, 243MB/s] \u001b[A\n",
            "model-00008-of-00014.safetensors:  16% 157M/967M [00:00<00:03, 245MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  20% 189M/967M [00:00<00:03, 242MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  23% 220M/967M [00:00<00:03, 241MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  26% 252M/967M [00:01<00:02, 250MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  29% 283M/967M [00:01<00:02, 251MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  33% 315M/967M [00:01<00:02, 251MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  36% 346M/967M [00:01<00:02, 251MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  39% 377M/967M [00:01<00:02, 243MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  42% 409M/967M [00:01<00:02, 243MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  46% 440M/967M [00:01<00:02, 246MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  49% 472M/967M [00:01<00:02, 246MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  52% 503M/967M [00:02<00:01, 254MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  55% 535M/967M [00:02<00:01, 247MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  59% 566M/967M [00:02<00:01, 249MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  62% 598M/967M [00:02<00:01, 253MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  65% 629M/967M [00:02<00:01, 253MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  68% 661M/967M [00:02<00:01, 246MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  72% 692M/967M [00:02<00:01, 252MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  75% 724M/967M [00:02<00:00, 244MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  78% 755M/967M [00:03<00:00, 247MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  81% 786M/967M [00:03<00:00, 246MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  85% 818M/967M [00:03<00:00, 252MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  88% 849M/967M [00:03<00:00, 240MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  91% 881M/967M [00:03<00:00, 244MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors:  94% 912M/967M [00:03<00:00, 245MB/s]\u001b[A\n",
            "model-00008-of-00014.safetensors: 100% 967M/967M [00:03<00:00, 246MB/s]\n",
            "Downloading shards:  57% 8/14 [00:42<00:30,  5.02s/it]\n",
            "model-00009-of-00014.safetensors:   0% 0.00/990M [00:00<?, ?B/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:   3% 31.5M/990M [00:00<00:03, 301MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:   6% 62.9M/990M [00:00<00:03, 295MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  10% 94.4M/990M [00:00<00:03, 276MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  13% 126M/990M [00:00<00:03, 253MB/s] \u001b[A\n",
            "model-00009-of-00014.safetensors:  16% 157M/990M [00:00<00:03, 260MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  19% 189M/990M [00:00<00:03, 248MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  22% 220M/990M [00:00<00:03, 253MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  25% 252M/990M [00:00<00:03, 244MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  29% 283M/990M [00:01<00:02, 247MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  32% 315M/990M [00:01<00:02, 246MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  35% 346M/990M [00:01<00:02, 247MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  38% 377M/990M [00:01<00:02, 221MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  41% 409M/990M [00:01<00:02, 213MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  44% 440M/990M [00:01<00:02, 207MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  48% 472M/990M [00:02<00:02, 205MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  51% 503M/990M [00:02<00:02, 219MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  54% 535M/990M [00:02<00:02, 223MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  57% 566M/990M [00:02<00:01, 223MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  60% 598M/990M [00:02<00:01, 214MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  64% 629M/990M [00:02<00:01, 191MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  66% 650M/990M [00:02<00:01, 195MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  69% 682M/990M [00:03<00:01, 201MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  72% 713M/990M [00:03<00:01, 211MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  75% 744M/990M [00:03<00:01, 205MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  77% 765M/990M [00:03<00:01, 194MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  79% 786M/990M [00:03<00:01, 198MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  82% 807M/990M [00:03<00:00, 198MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  84% 828M/990M [00:03<00:00, 199MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  86% 849M/990M [00:06<00:04, 28.7MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  88% 870M/990M [00:07<00:05, 22.3MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  91% 902M/990M [00:07<00:02, 34.3MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  94% 933M/990M [00:07<00:01, 49.8MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors:  97% 965M/990M [00:07<00:00, 67.3MB/s]\u001b[A\n",
            "model-00009-of-00014.safetensors: 100% 990M/990M [00:08<00:00, 123MB/s] \n",
            "Downloading shards:  64% 9/14 [00:50<00:30,  6.01s/it]\n",
            "model-00010-of-00014.safetensors:   0% 0.00/944M [00:00<?, ?B/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:   3% 31.5M/944M [00:00<00:03, 284MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:   7% 62.9M/944M [00:00<00:03, 290MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  10% 94.4M/944M [00:00<00:03, 272MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  13% 126M/944M [00:00<00:03, 248MB/s] \u001b[A\n",
            "model-00010-of-00014.safetensors:  17% 157M/944M [00:00<00:03, 251MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  20% 189M/944M [00:03<00:23, 32.3MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  23% 220M/944M [00:03<00:15, 45.7MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  27% 252M/944M [00:03<00:11, 62.5MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  30% 283M/944M [00:03<00:07, 83.2MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  33% 315M/944M [00:03<00:06, 102MB/s] \u001b[A\n",
            "model-00010-of-00014.safetensors:  37% 346M/944M [00:03<00:04, 122MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  40% 377M/944M [00:03<00:03, 144MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  43% 409M/944M [00:04<00:03, 164MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  47% 440M/944M [00:04<00:02, 182MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  50% 472M/944M [00:04<00:02, 203MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  53% 503M/944M [00:04<00:02, 218MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  57% 535M/944M [00:04<00:01, 224MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  60% 566M/944M [00:04<00:01, 233MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  63% 598M/944M [00:04<00:01, 236MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  67% 629M/944M [00:04<00:01, 233MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  70% 661M/944M [00:05<00:01, 234MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  73% 692M/944M [00:05<00:01, 239MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  77% 724M/944M [00:05<00:00, 245MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  80% 755M/944M [00:05<00:00, 246MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  83% 786M/944M [00:05<00:00, 246MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  87% 818M/944M [00:05<00:00, 245MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  90% 849M/944M [00:05<00:00, 247MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  93% 881M/944M [00:05<00:00, 249MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors:  97% 912M/944M [00:06<00:00, 251MB/s]\u001b[A\n",
            "model-00010-of-00014.safetensors: 100% 944M/944M [00:06<00:00, 151MB/s]\n",
            "Downloading shards:  71% 10/14 [00:57<00:24,  6.12s/it]\n",
            "model-00011-of-00014.safetensors:   0% 0.00/990M [00:00<?, ?B/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:   3% 31.5M/990M [00:00<00:03, 271MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:   6% 62.9M/990M [00:00<00:03, 272MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  10% 94.4M/990M [00:00<00:03, 269MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  13% 126M/990M [00:00<00:03, 218MB/s] \u001b[A\n",
            "model-00011-of-00014.safetensors:  16% 157M/990M [00:00<00:04, 197MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  18% 178M/990M [00:00<00:04, 181MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  20% 199M/990M [00:00<00:04, 180MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  22% 220M/990M [00:02<00:15, 49.2MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  24% 241M/990M [00:02<00:12, 62.1MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  26% 262M/990M [00:02<00:09, 77.0MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  29% 283M/990M [00:02<00:07, 92.5MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  31% 304M/990M [00:02<00:06, 109MB/s] \u001b[A\n",
            "model-00011-of-00014.safetensors:  33% 325M/990M [00:02<00:05, 121MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  35% 346M/990M [00:02<00:04, 134MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  37% 367M/990M [00:03<00:06, 103MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  40% 398M/990M [00:03<00:04, 138MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  43% 430M/990M [00:03<00:03, 168MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  47% 461M/990M [00:03<00:02, 196MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  50% 493M/990M [00:03<00:02, 209MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  53% 524M/990M [00:03<00:02, 210MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  56% 556M/990M [00:03<00:02, 213MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  59% 587M/990M [00:04<00:01, 227MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  62% 619M/990M [00:04<00:01, 232MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  66% 650M/990M [00:04<00:01, 245MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  69% 682M/990M [00:04<00:01, 246MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  72% 713M/990M [00:04<00:01, 246MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  75% 744M/990M [00:04<00:00, 254MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  78% 776M/990M [00:04<00:00, 255MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  82% 807M/990M [00:04<00:00, 247MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  85% 839M/990M [00:05<00:00, 248MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  88% 870M/990M [00:05<00:00, 259MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  91% 902M/990M [00:05<00:00, 251MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  94% 933M/990M [00:05<00:00, 253MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors:  97% 965M/990M [00:05<00:00, 248MB/s]\u001b[A\n",
            "model-00011-of-00014.safetensors: 100% 990M/990M [00:05<00:00, 173MB/s]\n",
            "Downloading shards:  79% 11/14 [01:02<00:18,  6.03s/it]\n",
            "model-00012-of-00014.safetensors:   0% 0.00/967M [00:00<?, ?B/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:   3% 31.5M/967M [00:00<00:03, 299MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:   7% 62.9M/967M [00:00<00:03, 283MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  10% 94.4M/967M [00:00<00:03, 255MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  13% 126M/967M [00:00<00:03, 253MB/s] \u001b[A\n",
            "model-00012-of-00014.safetensors:  16% 157M/967M [00:00<00:03, 252MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  20% 189M/967M [00:03<00:22, 34.1MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  23% 220M/967M [00:03<00:15, 48.0MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  26% 252M/967M [00:03<00:10, 65.4MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  29% 283M/967M [00:03<00:08, 84.0MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  33% 315M/967M [00:03<00:06, 105MB/s] \u001b[A\n",
            "model-00012-of-00014.safetensors:  36% 346M/967M [00:03<00:04, 128MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  39% 377M/967M [00:03<00:03, 151MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  42% 409M/967M [00:03<00:03, 168MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  46% 440M/967M [00:04<00:02, 189MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  49% 472M/967M [00:04<00:02, 201MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  52% 503M/967M [00:04<00:02, 215MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  55% 535M/967M [00:04<00:01, 232MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  59% 566M/967M [00:04<00:01, 242MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  62% 598M/967M [00:04<00:01, 249MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  65% 629M/967M [00:04<00:01, 248MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  68% 661M/967M [00:04<00:01, 250MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  72% 692M/967M [00:05<00:01, 250MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  75% 724M/967M [00:05<00:00, 254MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  78% 755M/967M [00:05<00:00, 249MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  81% 786M/967M [00:05<00:00, 250MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  85% 818M/967M [00:05<00:00, 254MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  88% 849M/967M [00:05<00:00, 246MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  91% 881M/967M [00:05<00:00, 253MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors:  94% 912M/967M [00:05<00:00, 244MB/s]\u001b[A\n",
            "model-00012-of-00014.safetensors: 100% 967M/967M [00:06<00:00, 156MB/s]\n",
            "Downloading shards:  86% 12/14 [01:09<00:12,  6.20s/it]\n",
            "model-00013-of-00014.safetensors:   0% 0.00/967M [00:00<?, ?B/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:   2% 21.0M/967M [00:00<00:06, 140MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:   5% 52.4M/967M [00:00<00:04, 194MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:   9% 83.9M/967M [00:00<00:03, 232MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  12% 115M/967M [00:00<00:03, 257MB/s] \u001b[A\n",
            "model-00013-of-00014.safetensors:  15% 147M/967M [00:00<00:03, 252MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  18% 178M/967M [00:00<00:03, 217MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  22% 210M/967M [00:00<00:03, 206MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  25% 241M/967M [00:01<00:03, 221MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  28% 273M/967M [00:01<00:03, 212MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  31% 304M/967M [00:01<00:03, 203MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  34% 325M/967M [00:01<00:03, 201MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  37% 357M/967M [00:01<00:02, 204MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  39% 377M/967M [00:04<00:23, 24.6MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  42% 409M/967M [00:05<00:16, 34.8MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  44% 430M/967M [00:05<00:15, 34.2MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  48% 461M/967M [00:05<00:10, 48.6MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  51% 493M/967M [00:05<00:07, 66.5MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  54% 524M/967M [00:06<00:05, 87.7MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  57% 556M/967M [00:06<00:03, 112MB/s] \u001b[A\n",
            "model-00013-of-00014.safetensors:  61% 587M/967M [00:06<00:02, 132MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  64% 619M/967M [00:06<00:02, 156MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  67% 650M/967M [00:06<00:01, 182MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  70% 682M/967M [00:06<00:01, 192MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  74% 713M/967M [00:06<00:01, 209MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  77% 744M/967M [00:06<00:01, 214MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  80% 776M/967M [00:07<00:00, 222MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  84% 807M/967M [00:07<00:00, 233MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  87% 839M/967M [00:07<00:00, 249MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  90% 870M/967M [00:07<00:00, 232MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  93% 902M/967M [00:07<00:00, 238MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors:  97% 933M/967M [00:07<00:00, 244MB/s]\u001b[A\n",
            "model-00013-of-00014.safetensors: 100% 967M/967M [00:07<00:00, 122MB/s]\n",
            "Downloading shards:  93% 13/14 [01:17<00:06,  6.75s/it]\n",
            "model-00014-of-00014.safetensors:   0% 0.00/847M [00:00<?, ?B/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:   4% 31.5M/847M [00:00<00:02, 296MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:   7% 62.9M/847M [00:00<00:02, 299MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  11% 94.4M/847M [00:00<00:02, 291MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  15% 126M/847M [00:00<00:02, 267MB/s] \u001b[A\n",
            "model-00014-of-00014.safetensors:  19% 157M/847M [00:00<00:02, 265MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  22% 189M/847M [00:00<00:02, 266MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  26% 220M/847M [00:00<00:02, 250MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  30% 252M/847M [00:00<00:02, 246MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  33% 283M/847M [00:01<00:02, 246MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  37% 315M/847M [00:01<00:02, 260MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  41% 346M/847M [00:01<00:01, 265MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  45% 377M/847M [00:01<00:01, 263MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  48% 409M/847M [00:01<00:01, 251MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  52% 440M/847M [00:02<00:04, 96.5MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  56% 472M/847M [00:02<00:03, 120MB/s] \u001b[A\n",
            "model-00014-of-00014.safetensors:  61% 514M/847M [00:02<00:02, 154MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  64% 545M/847M [00:02<00:01, 172MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  68% 577M/847M [00:02<00:01, 189MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  72% 608M/847M [00:03<00:01, 194MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  75% 640M/847M [00:03<00:01, 202MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  79% 671M/847M [00:03<00:00, 215MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  83% 703M/847M [00:03<00:00, 224MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  87% 734M/847M [00:03<00:00, 233MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  90% 765M/847M [00:03<00:00, 241MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors:  94% 797M/847M [00:03<00:00, 200MB/s]\u001b[A\n",
            "model-00014-of-00014.safetensors: 100% 847M/847M [00:04<00:00, 195MB/s]\n",
            "Downloading shards: 100% 14/14 [01:22<00:00,  5.86s/it]\n",
            "Loading checkpoint shards: 100% 14/14 [01:13<00:00,  5.26s/it]\n",
            "generation_config.json: 100% 132/132 [00:00<00:00, 781kB/s]\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-08-21 18:39:39\u001b[0m | \u001b[36mautotrain.trainers.clm.utils\u001b[0m:\u001b[36mget_model\u001b[0m:\u001b[36m666\u001b[0m - \u001b[1mmodel dtype: torch.float16\u001b[0m\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-08-21 18:39:39\u001b[0m | \u001b[36mautotrain.trainers.clm.train_clm_sft\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m39\u001b[0m - \u001b[1mcreating trainer\u001b[0m\n",
            "Generating train split: 0 examples [00:00, ? examples/s]Token indices sequence length is longer than the specified maximum sequence length for this model (3034 > 2048). Running this sequence through the model will result in indexing errors\n",
            "Generating train split: 1429 examples [00:05, 283.03 examples/s]\n",
            "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-08-21 18:39:48\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_train_begin\u001b[0m:\u001b[36m230\u001b[0m - \u001b[1mStarting to train...\u001b[0m\n",
            "  2% 23/1071 [07:01<5:27:02, 18.72s/it]\n",
            "events.out.tfevents.1724265588.d0ec91722827.3556.0: 100% 5.77k/5.77k [00:00<00:00, 27.2kB/s]\n",
            "  2% 25/1071 [07:39<5:29:35, 18.91s/it]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-08-21 18:47:27\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m225\u001b[0m - \u001b[1m{'loss': 1.2389, 'grad_norm': 0.3259412944316864, 'learning_rate': 4.62962962962963e-05, 'epoch': 0.06997900629811056}\u001b[0m\n",
            "{'loss': 1.2389, 'grad_norm': 0.3259412944316864, 'learning_rate': 4.62962962962963e-05, 'epoch': 0.07}\n",
            "  5% 50/1071 [15:26<5:17:28, 18.66s/it]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-08-21 18:55:14\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m225\u001b[0m - \u001b[1m{'loss': 1.1238, 'grad_norm': 0.7254876494407654, 'learning_rate': 9.25925925925926e-05, 'epoch': 0.13995801259622112}\u001b[0m\n",
            "{'loss': 1.1238, 'grad_norm': 0.7254876494407654, 'learning_rate': 9.25925925925926e-05, 'epoch': 0.14}\n",
            "  7% 73/1071 [22:35<5:10:05, 18.64s/it]\n",
            "events.out.tfevents.1724265588.d0ec91722827.3556.0:   0% 0.00/6.18k [00:00<?, ?B/s]\u001b[A\n",
            "events.out.tfevents.1724265588.d0ec91722827.3556.0: 100% 6.18k/6.18k [00:00<00:00, 21.4kB/s]\n",
            "  7% 75/1071 [23:14<5:16:59, 19.10s/it]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-08-21 19:03:03\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m225\u001b[0m - \u001b[1m{'loss': 1.0259, 'grad_norm': 0.35685020685195923, 'learning_rate': 0.0001388888888888889, 'epoch': 0.2099370188943317}\u001b[0m\n",
            "{'loss': 1.0259, 'grad_norm': 0.35685020685195923, 'learning_rate': 0.0001388888888888889, 'epoch': 0.21}\n",
            "  9% 100/1071 [31:01<5:01:57, 18.66s/it]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-08-21 19:10:49\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m225\u001b[0m - \u001b[1m{'loss': 1.0382, 'grad_norm': 0.340707927942276, 'learning_rate': 0.0001851851851851852, 'epoch': 0.27991602519244224}\u001b[0m\n",
            "{'loss': 1.0382, 'grad_norm': 0.340707927942276, 'learning_rate': 0.0001851851851851852, 'epoch': 0.28}\n",
            " 11% 123/1071 [38:09<4:52:37, 18.52s/it]\n",
            "events.out.tfevents.1724265588.d0ec91722827.3556.0: 100% 6.60k/6.60k [00:00<00:00, 30.6kB/s]\n",
            " 12% 125/1071 [38:52<5:09:51, 19.65s/it]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-08-21 19:18:40\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m225\u001b[0m - \u001b[1m{'loss': 0.9567, 'grad_norm': 0.36892592906951904, 'learning_rate': 0.0001964693665628245, 'epoch': 0.34989503149055284}\u001b[0m\n",
            "{'loss': 0.9567, 'grad_norm': 0.36892592906951904, 'learning_rate': 0.0001964693665628245, 'epoch': 0.35}\n",
            " 14% 150/1071 [46:39<4:45:53, 18.62s/it]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-08-21 19:26:27\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m225\u001b[0m - \u001b[1m{'loss': 1.0197, 'grad_norm': 0.3339720070362091, 'learning_rate': 0.0001912772585669782, 'epoch': 0.4198740377886634}\u001b[0m\n",
            "{'loss': 1.0197, 'grad_norm': 0.3339720070362091, 'learning_rate': 0.0001912772585669782, 'epoch': 0.42}\n",
            " 16% 173/1071 [53:47<4:38:24, 18.60s/it]\n",
            "events.out.tfevents.1724265588.d0ec91722827.3556.0:   0% 0.00/7.01k [00:00<?, ?B/s]\u001b[A\n",
            "events.out.tfevents.1724265588.d0ec91722827.3556.0: 100% 7.01k/7.01k [00:00<00:00, 23.7kB/s]\n",
            " 16% 175/1071 [54:26<4:42:53, 18.94s/it]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-08-21 19:34:14\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m225\u001b[0m - \u001b[1m{'loss': 0.9735, 'grad_norm': 0.32789480686187744, 'learning_rate': 0.0001860851505711319, 'epoch': 0.489853044086774}\u001b[0m\n",
            "{'loss': 0.9735, 'grad_norm': 0.32789480686187744, 'learning_rate': 0.0001860851505711319, 'epoch': 0.49}\n",
            " 19% 200/1071 [1:02:12<4:31:10, 18.68s/it]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-08-21 19:42:00\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m225\u001b[0m - \u001b[1m{'loss': 0.9927, 'grad_norm': 0.3219923973083496, 'learning_rate': 0.00018089304257528556, 'epoch': 0.5598320503848845}\u001b[0m\n",
            "{'loss': 0.9927, 'grad_norm': 0.3219923973083496, 'learning_rate': 0.00018089304257528556, 'epoch': 0.56}\n",
            " 21% 223/1071 [1:09:21<4:24:10, 18.69s/it]\n",
            "events.out.tfevents.1724265588.d0ec91722827.3556.0: 100% 7.44k/7.44k [00:00<00:00, 33.5kB/s]\n",
            " 21% 225/1071 [1:09:59<4:26:02, 18.87s/it]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-08-21 19:49:47\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m225\u001b[0m - \u001b[1m{'loss': 0.9559, 'grad_norm': 0.2769029140472412, 'learning_rate': 0.00017570093457943927, 'epoch': 0.6298110566829951}\u001b[0m\n",
            "{'loss': 0.9559, 'grad_norm': 0.2769029140472412, 'learning_rate': 0.00017570093457943927, 'epoch': 0.63}\n",
            " 23% 250/1071 [1:17:46<4:16:11, 18.72s/it]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-08-21 19:57:34\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m225\u001b[0m - \u001b[1m{'loss': 0.9221, 'grad_norm': 0.2736981511116028, 'learning_rate': 0.00017050882658359296, 'epoch': 0.6997900629811057}\u001b[0m\n",
            "{'loss': 0.9221, 'grad_norm': 0.2736981511116028, 'learning_rate': 0.00017050882658359296, 'epoch': 0.7}\n",
            " 25% 273/1071 [1:24:56<4:09:13, 18.74s/it]\n",
            "events.out.tfevents.1724265588.d0ec91722827.3556.0: 100% 7.86k/7.86k [00:00<00:00, 35.2kB/s]\n",
            " 26% 275/1071 [1:25:35<4:11:16, 18.94s/it]\u001b[1mINFO    \u001b[0m | \u001b[32m2024-08-21 20:05:23\u001b[0m | \u001b[36mautotrain.trainers.common\u001b[0m:\u001b[36mon_log\u001b[0m:\u001b[36m225\u001b[0m - \u001b[1m{'loss': 0.9561, 'grad_norm': 0.2732474207878113, 'learning_rate': 0.00016531671858774664, 'epoch': 0.7697690692792163}\u001b[0m\n",
            "{'loss': 0.9561, 'grad_norm': 0.2732474207878113, 'learning_rate': 0.00016531671858774664, 'epoch': 0.77}\n",
            " 26% 279/1071 [1:26:49<4:07:30, 18.75s/it]"
          ]
        }
      ],
      "source": [
        "!autotrain --config conf.yaml"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "03974b49f6ae49e187e3c6f0e0c93a15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2c9587db2b25402682871d2dccb7c6c7",
              "IPY_MODEL_c6b870ac173f41d2bbd76043373e5d22",
              "IPY_MODEL_80c3497ff05b472b955ac61bdea7c0e0"
            ],
            "layout": "IPY_MODEL_0e3cd45b9a0b4ea7a1d877b9a40a74f7"
          }
        },
        "2c9587db2b25402682871d2dccb7c6c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5691a37da8c4a899167a8be7a41b8f3",
            "placeholder": "​",
            "style": "IPY_MODEL_0f115277493144239079f87a2bfb547e",
            "value": "Downloading readme: 100%"
          }
        },
        "c6b870ac173f41d2bbd76043373e5d22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_553c02810a084785ba0428e2f66e537b",
            "max": 5337,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_181e6e0992e14651b796e0b4e5c9830b",
            "value": 5337
          }
        },
        "80c3497ff05b472b955ac61bdea7c0e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d39950daec34c138e61962cf7404b2d",
            "placeholder": "​",
            "style": "IPY_MODEL_0e89ed236c0647d3b2d4e8edd30059c3",
            "value": " 5.34k/5.34k [00:00&lt;00:00, 70.6kB/s]"
          }
        },
        "0e3cd45b9a0b4ea7a1d877b9a40a74f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5691a37da8c4a899167a8be7a41b8f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f115277493144239079f87a2bfb547e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "553c02810a084785ba0428e2f66e537b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "181e6e0992e14651b796e0b4e5c9830b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5d39950daec34c138e61962cf7404b2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e89ed236c0647d3b2d4e8edd30059c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f02628b7b9f949e59883ac8c4091e64a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ccef7bc62ce7431ebd015bc51189c381",
              "IPY_MODEL_2f4f721a79d04ceba0a967a1d1d759be",
              "IPY_MODEL_429f0859f87c4ad6bcdd81f09685d9ac"
            ],
            "layout": "IPY_MODEL_0dc9a0da0c4c4f4f83889a401ce00a8d"
          }
        },
        "ccef7bc62ce7431ebd015bc51189c381": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13942a750c404a87a51aa122fa60e19e",
            "placeholder": "​",
            "style": "IPY_MODEL_ad13c48a4f40417a8fe229d1bc2d0c38",
            "value": "Creating CSV from Arrow format: 100%"
          }
        },
        "2f4f721a79d04ceba0a967a1d1d759be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1ca68152ad14bc69de31cb73672128b",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_86f70dabaa714e5399e85a967e085432",
            "value": 4
          }
        },
        "429f0859f87c4ad6bcdd81f09685d9ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca5dd14ec11f43a0a6aa8d38a8e13714",
            "placeholder": "​",
            "style": "IPY_MODEL_afeccb4d3c4e4da0abd7748105f25f46",
            "value": " 4/4 [00:00&lt;00:00, 12.19ba/s]"
          }
        },
        "0dc9a0da0c4c4f4f83889a401ce00a8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13942a750c404a87a51aa122fa60e19e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad13c48a4f40417a8fe229d1bc2d0c38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b1ca68152ad14bc69de31cb73672128b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86f70dabaa714e5399e85a967e085432": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ca5dd14ec11f43a0a6aa8d38a8e13714": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afeccb4d3c4e4da0abd7748105f25f46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}